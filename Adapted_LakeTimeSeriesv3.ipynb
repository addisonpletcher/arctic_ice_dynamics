{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LGgPxn5kJfmq","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1696011843176,"user_tz":420,"elapsed":12,"user":{"displayName":"Addy Pletcher","userId":"00244907886130437420"}},"outputId":"5d3bff5b-1c71-49bc-bc7c-1d4855e9cb17"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nauthor: @ericslevenson\\ndate: 11/28/2022\\ndescription: GEE script to export near-daily records of lake area within a\\nshapefile of buffered lakes\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["'''\n","author: @ericslevenson\n","adapted by: @addisonpletcher\n","date: 11/28/2022\n","description: GEE script to export near-daily records of lake area within a\n","shapefile of buffered lakes\n","'''"]},{"cell_type":"markdown","metadata":{"id":"Kt-UVUejLtzO"},"source":["### Preliminary"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"K1xZzHHaKB0M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699404822392,"user_tz":480,"elapsed":18058,"user":{"displayName":"Addy Pletcher","userId":"00244907886130437420"}},"outputId":"8e2cfdbd-cbdd-4b06-b1c1-da7e368831c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n","\n","    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=QrczaEGh120F4EekvPpYCbcucQ8WA5XG-AcR-k6XTBc&tc=OER_LWr6iNq_PFA1pK5IQtylghDKTaVnNHgG7SjMr4k&cc=9gzapIjKtPEayZtfdG4TSF1fbyrMK_a7mMLYXviq32c\n","\n","The authorization workflow will generate a code, which you should paste in the box below.\n","Enter verification code: 4/1AfJohXmZs_fVXMsoxxeoh8EIB4fhsM1BYyhhZIbt5Yhu1yI4RsLgzZZ4AkM\n","\n","Successfully saved authorization token.\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Authenticate private account (only required for exporting to drive/gee/gcp)\n","#from google.colab import auth\n","#auth.authenticate_user()\n","\n","# Earth Engine setup\n","import ee # Trigger the authentication flow.\n","ee.Authenticate()\n","ee.Initialize() # Initialize the library.\n","\n","# Google Drive setup (if needed)\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"I3GpdMVWKFzj","executionInfo":{"status":"ok","timestamp":1699404828878,"user_tz":480,"elapsed":671,"user":{"displayName":"Addy Pletcher","userId":"00244907886130437420"}}},"outputs":[],"source":["## ***INPUTS***\n","\n","#TODO: can I remove tile stuff here since I'm not working off tiles? or should I work off tiles since I'm in specific UTM zones?\n","\n","## Regularly Adjusted inputs ##\n","# Time Period\n","start = '2018-06-29'\n","finish = '2018-07-01'\n","# Tile of interest\n","tile = 6    # since I'm not running via a tile scheme, can this be removed?\n","# Lake Shapefile\n","lakes = ee.FeatureCollection('projects/ee-addisonpletcher/assets/buffered_lakemask') # already a vector w/ buffered features\n","\n","## Periodically Adjusted Inputs ##\n","# ROI tile collection\n","tiles = ee.FeatureCollection('projects/ee-addisonpletcher/assets/test_ROI2')\n","\n","## Rarely Adjusted inputs ##\n","# Image scale\n","pixScale = 10\n","\n","# ***EXPORTS***\n","#TODO: remove centroid, add lat/long + Lake_ID. Removed FID\n","\n","# Export Properties\n","exportSelectors = ['id', 'Lake_ID', 'waterArea', 'clearArea', 'cloudArea', 'centroid'] # These will likely need to be changed to reflect your input shapefile. Specifically, 'count', 'centroid', and 'ratio' are all attributes from the imported EE asset. The others can stay the same.\n","# ROI Description\n","roiLabel = str('harmonized')\n","# Export Folder\n","exportFolder = 'YKD_water'\n","#TODO: reroute export folder to be 'raw_csvs', then also change where visualizations go\n","\n","\n","# ***EARTH ENGINE-IFY***\n","eestart = ee.Date(start)\n","eefinish = ee.Date(finish)\n","startDoy = ee.Date(start).getRelative('day', 'year')\n","endDoy = ee.Date(finish).getRelative('day', 'year')\n","# eeroi = tiles.filter(ee.Filter.eq('id', tile)).first() #don't filter, no tiles\n","eeroi = tiles.first()\n","roi = ee.Geometry.Polygon(eeroi.geometry().getInfo()['coordinates'][0])\n","lakes = lakes.filterBounds(roi) # filter lakes to roi"]},{"cell_type":"markdown","metadata":{"id":"t7SvYUcsTcMN"},"source":["### Functions"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"A6D112FJLqXV","executionInfo":{"status":"ok","timestamp":1699404832092,"user_tz":480,"elapsed":152,"user":{"displayName":"Addy Pletcher","userId":"00244907886130437420"}}},"outputs":[],"source":["## ***IMAGE PRE-PROCESSING METHODS***\n","\n","# Mask clouds in Sentinel-2\n","def maskS2clouds(image):\n","  '''Takes an input and adds two bands: cloud mask and clear mask'''\n","  qa = image.select('QA60')\n","  cloudBitMask = 1 << 10\n","  cirrusBitMask = 1 << 11\n","  clear_mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0)).rename('clear_mask')\n","  cloud_mask = qa.bitwiseAnd(cloudBitMask).eq(1).And(qa.bitwiseAnd(cirrusBitMask).eq(1)).rename('cloud_mask')\n","  return image.addBands([cloud_mask,clear_mask])\n","\n","# Clip image\n","def clip_image(image):\n","  '''Clips to the roi defined at the beginning of the script'''\n","  return image.clip(roi)\n","\n","def clip2lakes(image):\n","  '''Clips an image based on the lake boundaries'''\n","  return image.clip(lakes)\n","\n","# Get percentile cover\n","def getCover(image):\n","  '''calculates percentage of the roi covered by the clear mask. NOTE: this function\n","  calls the global totPixels variable that needs to be calculated in the main script.'''\n","  actArea = ee.Number(image.updateMask(image.select('B2')).reduceRegion(\n","      reducer = ee.Reducer.count(),\n","      scale = 100,\n","      maxPixels=1e12,\n","      ).values().get(0)).multiply(10000)\n","  # calculate the perc of cover OF CLEAR PIXELS\n","  percCover = actArea.divide(area).multiply(100)\n","  # number as output\n","  return image.set('percCover', percCover,'actArea',actArea)\n","\n","# Mosaic images by date, orbit, - basically combines images together that were taken on the same day\n","def mosaicBy(imcol):\n","  '''Takes an image collection (imcol) and creates a mosaic for each day\n","  Returns: An image collection of daily mosaics'''\n","  #return the collection as a list of images (not an image collection)\n","  imlist = imcol.toList(imcol.size())\n","  # Get all the dates as list\n","  def imdate(im):\n","    date = ee.Image(im).date().format(\"YYYY-MM-dd\")\n","    return date\n","  all_dates = imlist.map(imdate)\n","  # get all orbits as list\n","  def orbitId(im):\n","    orb = ee.Image(im).get('SENSING_ORBIT_NUMBER')\n","    return orb\n","  all_orbits = imlist.map(orbitId)\n","  # get all spacecraft names as list\n","  def spacecraft(im):\n","    return ee.Image(im).get('SPACECRAFT_NAME')\n","  all_spNames = imlist.map(spacecraft)\n","  # this puts dates, orbits and names into a nested list\n","  concat_all = all_dates.zip(all_orbits).zip(all_spNames);\n","  # here we unnest the list with flatten, and then concatenate the list elements with \" \"\n","  def concat(el):\n","    return ee.List(el).flatten().join(\" \")\n","  concat_all = concat_all.map(concat)\n","  # here, just get distinct combintations of date, orbit and name\n","  concat_unique = concat_all.distinct()\n","  # mosaic\n","  def mosaicIms(d):\n","    d1 = ee.String(d).split(\" \")\n","    date1 = ee.Date(d1.get(0))\n","    orbit = ee.Number.parse(d1.get(1)).toInt()\n","    spName = ee.String(d1.get(2))\n","    im = imcol.filterDate(date1, date1.advance(1, \"day\")).filterMetadata('SPACECRAFT_NAME', 'equals', spName).filterMetadata('SENSING_ORBIT_NUMBER','equals', orbit).mosaic()\n","    return im.set(\n","        \"system:time_start\", date1.millis(),\n","        \"system:date\", date1.format(\"YYYY-MM-dd\"),\n","        \"system:id\", d1)\n","  mosaic_imlist = concat_unique.map(mosaicIms)\n","  return ee.ImageCollection(mosaic_imlist)\n","\n","###########################################################################\n","## ***WATER CLASSIFICATION METHODS***\n","\n","# Define NDWI image\n","def ndwi(image):\n","  '''Adds an NDWI band to the input image'''\n","  return image.normalizedDifference(['B3', 'B8']).rename('NDWI').multiply(1000)\n","\n","# Basic ndwi classification\n","def ndwi_classify(image):\n","  '''Creates a binary image based on an NDWI threshold of 0'''\n","  ndwimask = image.select('NDWI')\n","  water = ndwimask.gte(0)\n","  land = ndwimask.lt(0)\n","  return(water)\n","\n","# OTSU thresholding from histogram\n","def otsu(histogram):\n","  '''Returns the NDWI threshold for binary water classification'''\n","  counts = ee.Array(ee.Dictionary(histogram).get('histogram'))\n","  means = ee.Array(ee.Dictionary(histogram).get('bucketMeans'))\n","  size = means.length().get([0])\n","  total = counts.reduce(ee.Reducer.sum(), [0]).get([0])\n","  sum = means.multiply(counts).reduce(ee.Reducer.sum(), [0]).get([0])\n","  mean = sum.divide(total)\n","  indices = ee.List.sequence(1, size)\n","  def func_xxx(i):\n","    '''Compute between sum of squares, where each mean partitions the data.'''\n","    aCounts = counts.slice(0, 0, i)\n","    aCount = aCounts.reduce(ee.Reducer.sum(), [0]).get([0])\n","    aMeans = means.slice(0, 0, i)\n","    aMean = aMeans.multiply(aCounts) \\\n","        .reduce(ee.Reducer.sum(), [0]).get([0]) \\\n","        .divide(aCount)\n","    bCount = total.subtract(aCount)\n","    bMean = sum.subtract(aCount.multiply(aMean)).divide(bCount)\n","    return aCount.multiply(aMean.subtract(mean).pow(2)).add(\n","           bCount.multiply(bMean.subtract(mean).pow(2)))\n","  bss = indices.map(func_xxx)\n","  # Return the mean value corresponding to the maximum BSS.\n","  return means.sort(bss).get([-1])\n","\n","# OTSU thresholding for an image\n","def otsu_thresh(water_image):\n","  '''Calculate NDWI and create histogram. Return the OTSU threshold.'''\n","  NDWI = ndwi(water_image).select('NDWI').updateMask(water_image.select('clear_mask'))\n","  histogram = ee.Dictionary(NDWI.reduceRegion(\n","    geometry = roi,\n","    reducer = ee.Reducer.histogram(255, 2).combine('mean', None, True).combine('variance', None, True),\n","    scale = pixScale,\n","    maxPixels = 1e12\n","  ))\n","  return otsu(histogram.get('NDWI_histogram'))\n","\n","# Classify an image using OTSU threshold.\n","def otsu_classify(water_image):\n","  '''(1) Calculate NDWI and create histogram. (2) Calculate NDWI threshold for\n","  binary classification using OTSU method. (3) Classify image and add layer to input image.\n","  '''\n","  NDWI = ndwi(water_image).select('NDWI')\n","  histogram = ee.Dictionary(NDWI.reduceRegion(\n","    geometry = roi,\n","    reducer = ee.Reducer.histogram(255, 2).combine('mean', None, True).combine('variance', None, True),\n","    scale = pixScale,\n","    maxPixels = 1e12\n","  ))\n","  threshold = otsu(histogram.get('NDWI_histogram'))\n","  otsu_classed = NDWI.gt(ee.Number(threshold)).And(water_image.select('B8').lt(2000)).rename('otsu_classed')\n","  return water_image.addBands([otsu_classed])\n","\n","def adaptive_thresholding(water_image):\n","  '''Takes an image clipped to lakes and returns the water mask'''\n","  NDWI = ndwi(water_image).select('NDWI')#.updateMask(water_image.select('clear_mask')) # get NDWI **TURNED OFF CLOUD MASK, SHOULD THIS STAY OFF?**\n","  threshold = ee.Number(otsu_thresh(water_image))\n","  threshold = threshold.divide(10).round().multiply(10)\n","  # get fixed histogram\n","  histo = NDWI.reduceRegion(\n","      geometry = roi,\n","      reducer = ee.Reducer.fixedHistogram(-1000, 1000, 200),\n","      scale = pixScale, # This was 30, keep at 10!?!?\n","      maxPixels = 1e12\n","  )\n","  hist = ee.Array(histo.get('NDWI'))\n","  counts = hist.cut([-1,1])\n","  buckets = hist.cut([-1,0])\n","  #find split points from otsu threshold\n","  threshold = ee.Array([threshold]).toList()\n","  buckets_list = buckets.toList()\n","  split = buckets_list.indexOf(threshold)\n","  # split into land and water slices\n","  land_slice = counts.slice(0,0,split)\n","  water_slice = counts.slice(0,split.add(1),-1)\n","  # find max of land and water slices\n","  land_max = land_slice.reduce(ee.Reducer.max(),[0])\n","  water_max = water_slice.reduce(ee.Reducer.max(),[0])\n","  land_max = land_max.toList().get(0)\n","  water_max = water_max.toList().get(0)\n","  land_max = ee.List(land_max).getNumber(0)\n","  water_max = ee.List(water_max).getNumber(0)\n","  #find difference between land, water and otsu val\n","  counts_list = counts.toList()\n","  otsu_val = ee.Number(counts_list.get(split))\n","  otsu_val = ee.List(otsu_val).getNumber(0)\n","  land_prom = ee.Number(land_max).subtract(otsu_val)\n","  water_prom = ee.Number(water_max).subtract(otsu_val)\n","  #find land and water buckets corresponding to 0.9 times the prominence\n","  land_thresh = ee.Number(land_max).subtract((land_prom).multiply(ee.Number(0.9)))\n","  water_thresh = ee.Number(water_max).subtract((water_prom).multiply(ee.Number(0.9)))\n","  land_max_ind = land_slice.argmax().get(0)\n","  water_max_ind = water_slice.argmax().get(0)\n","  li = ee.Number(land_max_ind).subtract(1)\n","  li = li.max(ee.Number(1))\n","  wi = ee.Number(water_max_ind).add(1)\n","  wi = wi.min(ee.Number(199))\n","  land_slice2 = land_slice.slice(0,li,-1).subtract(land_thresh)\n","  water_slice2 = water_slice.slice(0,0,wi).subtract(water_thresh)\n","  land_slice2  = land_slice2.abs().multiply(-1)\n","  water_slice2 = water_slice2.abs().multiply(-1)\n","  land_index = ee.Number(land_slice2.argmax().get(0)).add(land_max_ind)\n","  water_index = ee.Number(water_slice2.argmax().get(0)).add(split)\n","  land_level = ee.Number(buckets_list.get(land_index))\n","  water_level = ee.Number(buckets_list.get(water_index))\n","  land_level = ee.Number(ee.List(land_level).get(0)).add(5)\n","  water_level = ee.Number(ee.List(water_level).get(0)).add(5)\n","  #calculate water fraction and classify\n","  water_fraction = (NDWI.subtract(land_level)).divide(water_level.subtract(land_level)).multiply(100).rename('water_fraction')\n","  #water_fraction = conditional(water_fraction) #sets values less than 0 to 0 and greater than 100 to 100\n","  water_75 = water_fraction.gte(75).rename('water_75'); #note, this is a non-binary classification, so we use 75% water as \"water\"\n","  all_mask = water_image.select('B2').gt(5).rename('all_mask')\n","  cloud_mask_ed = water_image.select('clear_mask').neq(1).rename('cloud_mask_ed')\n","  return water_image.addBands([water_fraction,water_75,NDWI,cloud_mask_ed])\n","# Apply cloud mask to other bands\n","def applyMask(image):\n","  img = image.updateMask(image.select('clear_mask'))\n","  return img\n","def binaryImage(image):\n","  '''takes a multiband image and returns just the binary water_75 band'''\n","  img = image.select('water_75')\n","  return img\n","def waterImage(image):\n","  '''takes a multiband image and returns just the water fraction band'''\n","  img = image.select('water_fraction')\n","  return img\n","\n","###############################################################################\n","## ***PROPERTY EXTRACTION METHODS***\n","def sumWater(lake):\n","  '''sums the water pixels within a buffered lake polygon and adds the result to the feature'''\n","  watersum = waterAreaIm.select('area').reduceRegion(\n","      reducer=ee.Reducer.sum(),\n","      geometry = lake.geometry(),\n","      scale = 10,\n","      maxPixels=1e9\n","  ).get('area')\n","  return watersum\n","\n","def sumClear(lake):\n","  '''sums the number of clear pixels within a buffered lake polygon'''\n","  clearsum = lakeIm.select('clear_mask').reduceRegion(\n","      reducer=ee.Reducer.sum(),\n","      geometry = lake.geometry(),\n","      scale = 10,\n","      maxPixels=1e9\n","  ).get('clear_mask')\n","  return clearsum\n","\n","def getClearArea(lake):\n","  '''trying what i did with water...see if it works! Will potentialy switch for sumClear'''\n","  clearArea = clearAreaIm.select('area').reduceRegion(\n","      reducer=ee.Reducer.sum(),\n","      geometry = lake.geometry(),\n","      scale = 10,\n","      maxPixels=1e9\n","  ).get('area')\n","  return clearArea\n","\n","def sumClouds(lake):\n","  '''sums the number of clear pixels within a buffered lake polygon'''\n","  cloudsum = lakeIm.select('cloud_mask_ed').reduceRegion(\n","      reducer=ee.Reducer.sum(),\n","      geometry = lake.geometry(),\n","      scale = 10,\n","      maxPixels=1e9\n","  ).get('cloud_mask_ed')\n","  return cloudsum\n","\n","def getCloudArea(lake):\n","  '''trying what i did with water...see if it works! Will potentialy switch for sumClouds'''\n","  cloudArea = cloudAreaIm.select('area').reduceRegion(\n","      reducer=ee.Reducer.sum(),\n","      geometry = lake.geometry(),\n","      scale = 10,\n","      maxPixels=1e9\n","  ).get('area')\n","  return cloudArea\n","\n","def sumAll(lake):\n","  '''sums the number of pixels within a buffered lake polygon'''\n","  all_mask = lakeIm.select('B2').gt(5).rename('all_mask')\n","  allsum = all_mask.reduceRegion(\n","      reducer=ee.Reducer.count(),\n","      geometry = lake.geometry(),\n","      scale = 10,\n","      maxPixels=1e9\n","      ).get('all_mask')\n","  return allsum\n","\n","def troid(lake):\n","  center = ee.Array(lake.centroid().geometry().coordinates())\n","  return center\n","\n","def getID(lake):\n","  '''get the EarthEngine id'''\n","  id = ee.Number(lake.id())\n","  return id\n","\n","#originally FID, adapting for Lake_ID\n","def getLake_ID(lake):\n","  '''get the Lake_ID field from shapefile'''\n","  Lake_ID = ee.Number(lake.get('Lake_ID'))\n","  return Lake_ID\n","\n","####################TEST for above##################\n","#think its working based on Lake_ID being present in resulting csv, but can (and should) run more manual tests to ensure this is tru\n","####################TEST for above##################\n","\n","#def getCount(lake):\n","#  count = ee.Number(lake.get('count'))\n","#  return count\n","\n","\n","def lakeProps(lake):\n","  water = sumWater(lake)\n","  #clear = sumClear(lake)\n","  #clouds = sumClouds(lake)\n","  #all = sumAll(lake)\n","  centroid = troid(lake)\n","  id = getID(lake)\n","  #count = getCount(lake)\n","  #label = getLabel(lake)\n","  Lake_ID = getLake_ID(lake)\n","  cloudArea = getCloudArea(lake)\n","  clearArea = getClearArea(lake)\n","  return ee.Feature(None, {'id': id, 'Lake_ID': Lake_ID, 'waterArea': water, 'clearArea': clearArea,  'cloudArea': cloudArea, 'centroid': centroid})\n","  # deleted: 'allPixels': all, 'cloudPixels': clouds, 'clearPixels': clear, 'FID': fid\n","###############################################################################\n","## ***EXPORT METHODS***\n","def export_lakes(collection, description, fileNamePrefix, fileFormat, folder, selectors):\n","  '''Export a feature collection of lake properties to google drive for a given day.'''\n","  task = ee.batch.Export.table.toDrive(**{\n","    'collection': collection,\n","    'description': description,\n","    'fileNamePrefix': fileNamePrefix,\n","    'fileFormat': fileFormat,\n","    'folder': folder,\n","    'selectors': selectors\n","  })\n","  task.start()"]},{"cell_type":"markdown","metadata":{"id":"iodnIKGsLvl-"},"source":["## Main"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"heuw1Juc2btY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699404835900,"user_tz":480,"elapsed":1328,"user":{"displayName":"Addy Pletcher","userId":"00244907886130437420"}},"outputId":"bbc8bf00-2e2b-44f9-c048-3a8445e2e0a1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['2018-06-29', '2018-06-30']"]},"metadata":{},"execution_count":9}],"source":["##############################################################################\n","## *** IMAGE PROCESSING ***\n","images = ee.ImageCollection('COPERNICUS/S2_HARMONIZED').filterBounds(roi).filterDate(start,finish).filter(ee.Filter.calendarRange(startDoy, endDoy, 'day_of_year')).filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',50)) # Get Images\n","images_all = mosaicBy(images) # Mosaic images\n","images_all = images_all.map(maskS2clouds) # Create cloud/clear masks\n","images_all = images_all.map(clip_image) # Clip to roi\n","images_all.map(applyMask) # mask other bands for clouds\n","area = roi.area().getInfo() # Calculate total area\n","#area = roi.area()\n","#images_all = images_all.map(lambda image: image.set('total_area', area)) #workaround to remove getInfo function\n","\n","# Filter by percentile cover\n","images_all = images_all.map(getCover) # Add percent cover as an image property\n","images_all = images_all.filterMetadata('percCover','greater_than',10) # remove images covering less than 50% of the ROI)\n","lakeimages = images_all.map(clip2lakes) # Clip images to buffered lake mask\n","dates = lakeimages.aggregate_array('system:date').getInfo()\n","dates"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"98zfNETwTzLg","executionInfo":{"status":"ok","timestamp":1699404841857,"user_tz":480,"elapsed":1691,"user":{"displayName":"Addy Pletcher","userId":"00244907886130437420"}}},"outputs":[],"source":["###############################################################################\n","## ***WATER CLASSIFICATION***\n","lakeimages = lakeimages.map(adaptive_thresholding)\n","\n","###############################################################################\n","## ***ITERATE THROUGH DAYS AND EXPORT***\n","for i, date in enumerate(dates):\n","  # Get lake properties\n","  eedate = ee.Date(date) #earthengine date format\n","  lakeIm = lakeimages.filterDate(eedate).first() # get the appropriate date\n","  areaIm = lakeIm.pixelArea() # get a pixel area image\n","  lakeIm = lakeIm.addBands([areaIm]) # add pixel area as a band in the image\n","  waterAreaIm = areaIm.updateMask(lakeIm.select('water_75')) # mask area image based on water\n","  cloudAreaIm = areaIm.updateMask(lakeIm.select('cloud_mask_ed')) # mask area image based on clouds\n","  clearAreaIm = areaIm.updateMask(lakeIm.select('clear_mask')) # mask area image based on clearness\n","  lakes2 = lakes.map(lakeProps)\n","  # Export\n","  exportDate = date.replace('-', '_')\n","  description = roiLabel +'_'+ exportDate\n","  fileformat = 'CSV'\n","  export_lakes(lakes2, description, description, fileformat, exportFolder, exportSelectors)"]},{"cell_type":"code","source":["test = lakes2.first()\n","test.getInfo()"],"metadata":{"id":"KzlOL8n_nxvZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualization\n","###### *** When exporting image need to uncheck \"include read only scopes\" during authentication ***"],"metadata":{"id":"kdDqGFnRboxq"}},{"cell_type":"markdown","source":["#### Classified Image Export (single)"],"metadata":{"id":"feXtg6sC7kzc"}},{"cell_type":"code","source":["#Original visualization\n","single = lakeimages.first().select('water_75', 'cloud_mask', 'clear_mask')\n","\n","# Cast all bands to UInt 8\n","single = single.toUint8() #exporting image w/ binary classifications ranging from 0-1, so UInt8\n","\n","task = ee.batch.Export.image.toDrive(**{\n","    'image': single,\n","    'description': 'test_img',\n","    'folder':'Visualization',\n","    'fileFormat': 'GeoTIFF',\n","    'scale': 10,\n","    'region': roi,\n","    'maxPixels': 1e12\n","})\n","task.start()\n","import time\n","while task.active():\n","  print('Polling for task (id: {}).'.format(task.id))\n","  time.sleep(5)"],"metadata":{"id":"8KpqOa167pgC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Classified Image Export (Collection)"],"metadata":{"id":"GQlLy32SZAgJ"}},{"cell_type":"code","source":["import folium\n","import time\n","\n","# Define what bands\n","bands_to_select = ['water_75', 'cloud_mask', 'clear_mask']\n","\n","# Iterate through the Image Collection and export each image\n","image_list = lakeimages.toList(lakeimages.size())\n","for i in range(image_list.length().getInfo()):\n","    # Get the current image in the collection\n","    current_image = ee.Image(image_list.get(i))\n","\n","    # Select the desired bands and cast to UInt8\n","    selected_image = current_image.select(bands_to_select).toUint8()\n","\n","    # Get the date from the image's metadata\n","    date = ee.Date(current_image.get('system:time_start'))\n","    date_str = date.format('YYYY-MM-dd').getInfo()  # Format the date as desired\n","\n","    # Use the date as the description\n","    description = 'image_' + date_str\n","\n","    # Define the export task for the current image\n","    task = ee.batch.Export.image.toDrive(**{\n","        'image': selected_image,\n","        'description': description,\n","        'folder': 'Visualization', #have this foler be mapped within YKD_Water folder\n","        'fileFormat': 'GeoTIFF',\n","        'scale': 10,\n","        'region': roi,\n","        'maxPixels': 1e12\n","    })\n","\n","    # Start the export task for the current image\n","    task.start()\n","\n","    # Monitor the task's progress\n","    print('Exporting task (id: {}) - Image {}'.format(task.id, i))\n","\n","    # Wait for the task to complete before moving on to the next image\n","    while task.active():\n","        print('Polling for task (id: {}).'.format(task.id))\n","        time.sleep(5)\n"],"metadata":{"id":"-8a4eCeYyOkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["single = lakeimages.first().select('water_75', 'cloud_mask', 'clear_mask')\n","single.getInfo()"],"metadata":{"id":"Yl4hzj3UKksu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698787234075,"user_tz":420,"elapsed":41915,"user":{"displayName":"Addy Pletcher","userId":"00244907886130437420"}},"outputId":"26afb213-69e5-4d35-b800-c8541a09f0ec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'type': 'Image',\n"," 'bands': [{'id': 'water_75',\n","   'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 1},\n","   'dimensions': [4, 2],\n","   'origin': [-165, 60],\n","   'crs': 'EPSG:4326',\n","   'crs_transform': [1, 0, 0, 0, 1, 0]},\n","  {'id': 'cloud_mask',\n","   'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 1},\n","   'dimensions': [4, 2],\n","   'origin': [-165, 60],\n","   'crs': 'EPSG:4326',\n","   'crs_transform': [1, 0, 0, 0, 1, 0]},\n","  {'id': 'clear_mask',\n","   'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 1},\n","   'dimensions': [4, 2],\n","   'origin': [-165, 60],\n","   'crs': 'EPSG:4326',\n","   'crs_transform': [1, 0, 0, 0, 1, 0]}],\n"," 'id': ['2018-06-29', '115.0', 'Sentinel-2B'],\n"," 'properties': {'percCover': 191.45828477625665,\n","  'actArea': 12999650000,\n","  'system:time_start': 1530230400000,\n","  'system:date': '2018-06-29',\n","  'system:index': '0'}}"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["# TRY #1\n","# not functional because i have a feature collection not img collection\n","\n","import folium\n","\n","lakes_collection = ee.ImageCollection('lakes2')\n","\n","# Define the export parameters\n","export_params = {\n","    'folder': 'my_export_folder',\n","    'scale': 30,  # Set the scale to your desired value\n","    'fileFormat': 'GeoTIFF',\n","}\n","\n","# Iterate through the image collection and export each image\n","image_list = lakes_collection.toList(lakes_collection.size())\n","for i in range(image_list.length().getInfo()):\n","    image = ee.Image(image_list.get(i))\n","    export_params['image'] = image\n","    export_params['description'] = 'export_' + str(i)  # Change the description as needed\n","    task = ee.batch.Export.image.toDrive(**export_params)\n","    task.start()\n"],"metadata":{"id":"0Zuorvkxbsv6"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/ericslevenson/arctic-surface-water/blob/main/LakeTimeSeriesv3.ipynb","timestamp":1688587554668}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}